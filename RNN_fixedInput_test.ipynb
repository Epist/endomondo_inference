{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata\n",
      "Metadata loaded\n",
      "Starting with 1 inputs\n",
      "Epoch: 1 Learning rate: 1.000000\n",
      "0.039 RMSE: 0.851754 speed: 5478 dpps\n",
      "0.136 RMSE: 0.513046 speed: 7150 dpps\n",
      "0.233 RMSE: 0.398242 speed: 7578 dpps\n",
      "0.329 RMSE: 0.321631 speed: 7826 dpps\n",
      "0.426 RMSE: 0.282278 speed: 7870 dpps\n",
      "0.523 RMSE: 0.257669 speed: 7982 dpps\n",
      "0.620 RMSE: 0.238782 speed: 8091 dpps\n",
      "0.717 RMSE: 0.225132 speed: 8137 dpps\n",
      "0.814 RMSE: 0.215297 speed: 8220 dpps\n",
      "0.911 RMSE: 0.205776 speed: 8244 dpps\n",
      "Epoch: 1 Train RMSE: 0.199482\n",
      "0.039 RMSE: 0.135242 speed: 8884 dpps\n",
      "0.136 RMSE: 0.130104 speed: 12951 dpps\n",
      "0.233 RMSE: 0.122226 speed: 13669 dpps\n",
      "0.329 RMSE: 0.127157 speed: 14521 dpps\n",
      "0.426 RMSE: 0.134675 speed: 14822 dpps\n",
      "0.523 RMSE: 0.134314 speed: 15036 dpps\n",
      "0.620 RMSE: 0.134092 speed: 15424 dpps\n",
      "0.717 RMSE: 0.135571 speed: 15502 dpps\n",
      "0.814 RMSE: 0.133395 speed: 15430 dpps\n",
      "0.911 RMSE: 0.132136 speed: 15464 dpps\n",
      "Saving data to file\n",
      "Epoch: 1 Valid RMSE: 0.132471\n",
      "Epoch: 2 Learning rate: 1.000000\n",
      "0.039 RMSE: 0.187958 speed: 7535 dpps\n",
      "0.136 RMSE: 0.177413 speed: 8209 dpps\n",
      "0.233 RMSE: 0.158332 speed: 8081 dpps\n",
      "0.329 RMSE: 0.154081 speed: 8089 dpps\n",
      "0.426 RMSE: 0.152535 speed: 8082 dpps\n",
      "0.523 RMSE: 0.149423 speed: 8082 dpps\n",
      "0.620 RMSE: 0.151859 speed: 8105 dpps\n",
      "0.717 RMSE: 0.150168 speed: 8085 dpps\n",
      "0.814 RMSE: 0.148829 speed: 8101 dpps\n",
      "0.911 RMSE: 0.147744 speed: 8116 dpps\n",
      "Epoch: 2 Train RMSE: 0.147251\n",
      "0.039 RMSE: 0.139824 speed: 8989 dpps\n",
      "0.136 RMSE: 0.135355 speed: 12966 dpps\n",
      "0.233 RMSE: 0.132117 speed: 14248 dpps\n",
      "0.329 RMSE: 0.138461 speed: 14926 dpps\n",
      "0.426 RMSE: 0.136432 speed: 15234 dpps\n",
      "0.523 RMSE: 0.134727 speed: 15492 dpps\n",
      "0.620 RMSE: 0.134981 speed: 15743 dpps\n",
      "0.717 RMSE: 0.132568 speed: 15789 dpps\n",
      "0.814 RMSE: 0.131957 speed: 15720 dpps\n",
      "0.911 RMSE: 0.131891 speed: 15725 dpps\n",
      "Saving data to file\n",
      "Epoch: 2 Valid RMSE: 0.131436\n",
      "Epoch: 3 Learning rate: 1.000000\n",
      "0.039 RMSE: 0.170407 speed: 8653 dpps\n",
      "0.136 RMSE: 0.135056 speed: 8315 dpps\n",
      "0.233 RMSE: 0.138718 speed: 8066 dpps\n",
      "0.329 RMSE: 0.140383 speed: 8091 dpps\n",
      "0.426 RMSE: 0.146226 speed: 8045 dpps\n",
      "0.523 RMSE: 0.142196 speed: 8076 dpps\n",
      "0.620 RMSE: 0.141253 speed: 8045 dpps\n",
      "0.717 RMSE: 0.139899 speed: 8077 dpps\n",
      "0.814 RMSE: 0.137809 speed: 8104 dpps\n",
      "0.911 RMSE: 0.137607 speed: 8078 dpps\n",
      "Epoch: 3 Train RMSE: 0.137053\n",
      "0.039 RMSE: 0.121890 speed: 9038 dpps\n",
      "0.136 RMSE: 0.123176 speed: 13050 dpps\n",
      "0.233 RMSE: 0.123227 speed: 13980 dpps\n",
      "0.329 RMSE: 0.125791 speed: 14745 dpps\n",
      "0.426 RMSE: 0.127727 speed: 14710 dpps\n",
      "0.523 RMSE: 0.128198 speed: 15054 dpps\n",
      "0.620 RMSE: 0.131446 speed: 15211 dpps\n",
      "0.717 RMSE: 0.132786 speed: 15125 dpps\n",
      "0.814 RMSE: 0.131948 speed: 15361 dpps\n",
      "0.911 RMSE: 0.134693 speed: 15412 dpps\n",
      "Saving data to file\n",
      "Epoch: 3 Valid RMSE: 0.134032\n",
      "Epoch: 4 Learning rate: 1.000000\n",
      "0.039 RMSE: 0.152682 speed: 8102 dpps\n",
      "0.136 RMSE: 0.131834 speed: 8189 dpps\n",
      "0.233 RMSE: 0.131099 speed: 8224 dpps\n",
      "0.329 RMSE: 0.133670 speed: 8319 dpps\n",
      "0.426 RMSE: 0.134197 speed: 8333 dpps\n",
      "0.523 RMSE: 0.133479 speed: 8366 dpps\n",
      "0.620 RMSE: 0.136814 speed: 8291 dpps\n",
      "0.717 RMSE: 0.137131 speed: 8250 dpps\n",
      "0.814 RMSE: 0.135570 speed: 8270 dpps\n",
      "0.911 RMSE: 0.133932 speed: 8258 dpps\n",
      "Epoch: 4 Train RMSE: 0.136346\n",
      "0.039 RMSE: 0.165013 speed: 11333 dpps\n",
      "0.136 RMSE: 0.163498 speed: 14327 dpps\n",
      "0.233 RMSE: 0.162989 speed: 15236 dpps\n",
      "0.329 RMSE: 0.155469 speed: 15548 dpps\n",
      "0.426 RMSE: 0.147220 speed: 15668 dpps\n",
      "0.523 RMSE: 0.142146 speed: 16019 dpps\n",
      "0.620 RMSE: 0.139602 speed: 16061 dpps\n",
      "0.717 RMSE: 0.139042 speed: 15983 dpps\n",
      "0.814 RMSE: 0.137772 speed: 16029 dpps\n",
      "0.911 RMSE: 0.138765 speed: 15925 dpps\n",
      "Saving data to file\n",
      "Epoch: 4 Valid RMSE: 0.138169\n",
      "Epoch: 5 Learning rate: 1.000000\n",
      "0.039 RMSE: 0.162214 speed: 8200 dpps\n",
      "0.136 RMSE: 0.141826 speed: 8185 dpps\n",
      "0.233 RMSE: 0.139079 speed: 8121 dpps\n",
      "0.329 RMSE: 0.141048 speed: 8009 dpps\n",
      "0.426 RMSE: 0.143839 speed: 8004 dpps\n",
      "0.523 RMSE: 0.139466 speed: 8076 dpps\n",
      "0.620 RMSE: 0.140368 speed: 8087 dpps\n",
      "0.717 RMSE: 0.139643 speed: 8108 dpps\n",
      "0.814 RMSE: 0.137200 speed: 8114 dpps\n",
      "0.911 RMSE: 0.138212 speed: 8158 dpps\n",
      "Epoch: 5 Train RMSE: 0.136657\n",
      "0.039 RMSE: 0.129411 speed: 9491 dpps\n",
      "0.136 RMSE: 0.135188 speed: 13266 dpps\n",
      "0.233 RMSE: 0.142745 speed: 14342 dpps\n",
      "0.329 RMSE: 0.139558 speed: 15082 dpps\n",
      "0.426 RMSE: 0.139494 speed: 15035 dpps\n",
      "0.523 RMSE: 0.141253 speed: 15047 dpps\n",
      "0.620 RMSE: 0.140893 speed: 15043 dpps\n",
      "0.717 RMSE: 0.141768 speed: 15196 dpps\n",
      "0.814 RMSE: 0.139995 speed: 15296 dpps\n",
      "0.911 RMSE: 0.141538 speed: 15402 dpps\n",
      "Saving data to file\n",
      "Epoch: 5 Valid RMSE: 0.141794\n",
      "Epoch: 6 Learning rate: 1.000000\n",
      "0.039 RMSE: 0.131010 speed: 7974 dpps\n",
      "0.136 RMSE: 0.148859 speed: 8044 dpps\n",
      "0.233 RMSE: 0.144037 speed: 8042 dpps\n",
      "0.329 RMSE: 0.144561 speed: 8166 dpps\n",
      "0.426 RMSE: 0.144171 speed: 8180 dpps\n",
      "0.523 RMSE: 0.144061 speed: 8208 dpps\n",
      "0.620 RMSE: 0.142599 speed: 8207 dpps\n",
      "0.717 RMSE: 0.141001 speed: 8235 dpps\n",
      "0.814 RMSE: 0.141065 speed: 8246 dpps\n",
      "0.911 RMSE: 0.139734 speed: 8287 dpps\n",
      "Epoch: 6 Train RMSE: 0.139230\n",
      "0.039 RMSE: 0.132558 speed: 9484 dpps\n",
      "0.136 RMSE: 0.123898 speed: 12150 dpps\n",
      "0.233 RMSE: 0.134690 speed: 13416 dpps\n",
      "0.329 RMSE: 0.142380 speed: 14057 dpps\n",
      "0.426 RMSE: 0.136922 speed: 14400 dpps\n",
      "0.523 RMSE: 0.135601 speed: 14703 dpps\n",
      "0.620 RMSE: 0.136936 speed: 14767 dpps\n",
      "0.717 RMSE: 0.139216 speed: 14932 dpps\n",
      "0.814 RMSE: 0.141172 speed: 15121 dpps\n",
      "0.911 RMSE: 0.139761 speed: 15255 dpps\n",
      "Saving data to file\n",
      "Epoch: 6 Valid RMSE: 0.138982\n",
      "Epoch: 7 Learning rate: 0.950000\n",
      "0.039 RMSE: 0.109187 speed: 7973 dpps\n",
      "0.136 RMSE: 0.161058 speed: 8403 dpps\n",
      "0.233 RMSE: 0.152020 speed: 8274 dpps\n",
      "0.329 RMSE: 0.150698 speed: 8298 dpps\n",
      "0.426 RMSE: 0.142578 speed: 8177 dpps\n",
      "0.523 RMSE: 0.140666 speed: 8152 dpps\n",
      "0.620 RMSE: 0.141549 speed: 8219 dpps\n",
      "0.717 RMSE: 0.140280 speed: 8209 dpps\n",
      "0.814 RMSE: 0.138328 speed: 8256 dpps\n",
      "0.911 RMSE: 0.137921 speed: 8262 dpps\n",
      "Epoch: 7 Train RMSE: 0.139146\n",
      "0.039 RMSE: 0.153270 speed: 9945 dpps\n",
      "0.136 RMSE: 0.124465 speed: 12916 dpps\n",
      "0.233 RMSE: 0.136598 speed: 13232 dpps\n",
      "0.329 RMSE: 0.136192 speed: 13894 dpps\n",
      "0.426 RMSE: 0.135763 speed: 14407 dpps\n",
      "0.523 RMSE: 0.133452 speed: 14429 dpps\n",
      "0.620 RMSE: 0.131905 speed: 14684 dpps\n",
      "0.717 RMSE: 0.129377 speed: 14947 dpps\n",
      "0.814 RMSE: 0.128299 speed: 15059 dpps\n",
      "0.911 RMSE: 0.129674 speed: 15264 dpps\n",
      "Saving data to file\n",
      "Epoch: 7 Valid RMSE: 0.129738\n",
      "Epoch: 8 Learning rate: 0.902500\n",
      "0.039 RMSE: 0.106331 speed: 8388 dpps\n",
      "0.136 RMSE: 0.126655 speed: 8260 dpps\n",
      "0.233 RMSE: 0.128191 speed: 8264 dpps\n",
      "0.329 RMSE: 0.135388 speed: 8253 dpps\n",
      "0.426 RMSE: 0.131448 speed: 8230 dpps\n",
      "0.523 RMSE: 0.134961 speed: 8222 dpps\n",
      "0.620 RMSE: 0.133604 speed: 8260 dpps\n",
      "0.717 RMSE: 0.134983 speed: 8309 dpps\n",
      "0.814 RMSE: 0.134185 speed: 8323 dpps\n",
      "0.911 RMSE: 0.135119 speed: 8306 dpps\n",
      "Epoch: 8 Train RMSE: 0.133493\n",
      "0.039 RMSE: 0.111235 speed: 11309 dpps\n",
      "0.136 RMSE: 0.133238 speed: 13941 dpps\n",
      "0.233 RMSE: 0.125218 speed: 14436 dpps\n",
      "0.329 RMSE: 0.123680 speed: 15083 dpps\n",
      "0.426 RMSE: 0.126466 speed: 15289 dpps\n",
      "0.523 RMSE: 0.127996 speed: 15560 dpps\n",
      "0.620 RMSE: 0.127323 speed: 15840 dpps\n",
      "0.717 RMSE: 0.131148 speed: 15969 dpps\n",
      "0.814 RMSE: 0.130441 speed: 15822 dpps\n",
      "0.911 RMSE: 0.130857 speed: 15897 dpps\n",
      "Saving data to file\n",
      "Epoch: 8 Valid RMSE: 0.134202\n",
      "Epoch: 9 Learning rate: 0.857375\n",
      "0.039 RMSE: 0.115411 speed: 8072 dpps\n",
      "0.136 RMSE: 0.133683 speed: 8333 dpps\n",
      "0.233 RMSE: 0.253126 speed: 8391 dpps\n",
      "0.329 RMSE: 0.217822 speed: 8401 dpps\n",
      "0.426 RMSE: 0.197555 speed: 8362 dpps\n",
      "0.523 RMSE: 0.184606 speed: 8341 dpps\n",
      "0.620 RMSE: 0.177143 speed: 8344 dpps\n",
      "0.717 RMSE: 0.174066 speed: 8331 dpps\n",
      "0.814 RMSE: 0.169405 speed: 8323 dpps\n",
      "0.911 RMSE: 0.164584 speed: 8317 dpps\n",
      "Epoch: 9 Train RMSE: 0.161871\n",
      "0.039 RMSE: 0.123018 speed: 10178 dpps\n",
      "0.136 RMSE: 0.124487 speed: 13313 dpps\n",
      "0.233 RMSE: 0.128887 speed: 14442 dpps\n",
      "0.329 RMSE: 0.131678 speed: 14720 dpps\n",
      "0.426 RMSE: 0.129429 speed: 14978 dpps\n",
      "0.523 RMSE: 0.128468 speed: 15234 dpps\n",
      "0.620 RMSE: 0.129995 speed: 15524 dpps\n",
      "0.717 RMSE: 0.130687 speed: 15691 dpps\n",
      "0.814 RMSE: 0.128744 speed: 15694 dpps\n",
      "0.911 RMSE: 0.132687 speed: 15739 dpps\n",
      "Saving data to file\n",
      "Epoch: 9 Valid RMSE: 0.131525\n",
      "Epoch: 10 Learning rate: 0.814506\n",
      "0.039 RMSE: 0.121917 speed: 8422 dpps\n",
      "0.136 RMSE: 0.128835 speed: 8262 dpps\n",
      "0.233 RMSE: 0.131727 speed: 8235 dpps\n",
      "0.329 RMSE: 0.143720 speed: 8281 dpps\n",
      "0.426 RMSE: 0.141833 speed: 8249 dpps\n",
      "0.523 RMSE: 0.143199 speed: 8054 dpps\n",
      "0.620 RMSE: 0.141037 speed: 7973 dpps\n",
      "0.717 RMSE: 0.140117 speed: 8022 dpps\n",
      "0.814 RMSE: 0.140919 speed: 8036 dpps\n",
      "0.911 RMSE: 0.141744 speed: 8018 dpps\n",
      "Epoch: 10 Train RMSE: 0.140573\n",
      "0.039 RMSE: 0.146209 speed: 10966 dpps\n",
      "0.136 RMSE: 0.137790 speed: 14063 dpps\n",
      "0.233 RMSE: 0.145976 speed: 15467 dpps\n",
      "0.329 RMSE: 0.153379 speed: 15827 dpps\n",
      "0.426 RMSE: 0.146635 speed: 15872 dpps\n",
      "0.523 RMSE: 0.148468 speed: 15916 dpps\n",
      "0.620 RMSE: 0.144571 speed: 15909 dpps\n",
      "0.717 RMSE: 0.143665 speed: 15638 dpps\n",
      "0.814 RMSE: 0.143179 speed: 15926 dpps\n",
      "0.911 RMSE: 0.140181 speed: 16099 dpps\n",
      "Saving data to file\n",
      "Epoch: 10 Valid RMSE: 0.138184\n",
      "Epoch: 11 Learning rate: 0.773781\n",
      "0.039 RMSE: 0.131376 speed: 7938 dpps\n",
      "0.136 RMSE: 0.124194 speed: 8014 dpps\n",
      "0.233 RMSE: 0.122897 speed: 7993 dpps\n",
      "0.329 RMSE: 0.125742 speed: 8114 dpps\n",
      "0.426 RMSE: 0.135219 speed: 8208 dpps\n",
      "0.523 RMSE: 0.133343 speed: 8288 dpps\n",
      "0.620 RMSE: 0.132117 speed: 8240 dpps\n",
      "0.717 RMSE: 0.131090 speed: 8310 dpps\n",
      "0.814 RMSE: 0.131906 speed: 8271 dpps\n",
      "0.911 RMSE: 0.131131 speed: 8273 dpps\n",
      "Epoch: 11 Train RMSE: 0.131599\n",
      "0.039 RMSE: 0.136870 speed: 8624 dpps\n",
      "0.136 RMSE: 0.157048 speed: 13365 dpps\n",
      "0.233 RMSE: 0.145862 speed: 14716 dpps\n",
      "0.329 RMSE: 0.137669 speed: 15424 dpps\n",
      "0.426 RMSE: 0.133141 speed: 15584 dpps\n",
      "0.523 RMSE: 0.131435 speed: 15942 dpps\n",
      "0.620 RMSE: 0.130311 speed: 15936 dpps\n",
      "0.717 RMSE: 0.132600 speed: 15674 dpps\n",
      "0.814 RMSE: 0.131790 speed: 15500 dpps\n",
      "0.911 RMSE: 0.132742 speed: 15492 dpps\n",
      "Saving data to file\n",
      "Epoch: 11 Valid RMSE: 0.132503\n",
      "Epoch: 12 Learning rate: 0.735092\n",
      "0.039 RMSE: 0.135334 speed: 8024 dpps\n",
      "0.136 RMSE: 0.167935 speed: 7794 dpps\n",
      "0.233 RMSE: 0.148206 speed: 7951 dpps\n",
      "0.329 RMSE: 0.139270 speed: 8028 dpps\n",
      "0.426 RMSE: 0.136142 speed: 8051 dpps\n",
      "0.523 RMSE: 0.135517 speed: 8012 dpps\n",
      "0.620 RMSE: 0.134885 speed: 8050 dpps\n",
      "0.717 RMSE: 0.134689 speed: 8027 dpps\n",
      "0.814 RMSE: 0.136144 speed: 8023 dpps\n",
      "0.911 RMSE: 0.138010 speed: 8065 dpps\n",
      "Epoch: 12 Train RMSE: 0.138087\n",
      "0.039 RMSE: 0.227202 speed: 10362 dpps\n",
      "0.136 RMSE: 0.157198 speed: 14797 dpps\n",
      "0.233 RMSE: 0.157491 speed: 15392 dpps\n",
      "0.329 RMSE: 0.153541 speed: 15230 dpps\n",
      "0.426 RMSE: 0.146807 speed: 15332 dpps\n",
      "0.523 RMSE: 0.143640 speed: 15706 dpps\n",
      "0.620 RMSE: 0.142145 speed: 15644 dpps\n",
      "0.717 RMSE: 0.145358 speed: 15478 dpps\n",
      "0.814 RMSE: 0.144709 speed: 15615 dpps\n",
      "0.911 RMSE: 0.141875 speed: 15750 dpps\n",
      "Saving data to file\n",
      "Epoch: 12 Valid RMSE: 0.139912\n",
      "Epoch: 13 Learning rate: 0.698337\n",
      "0.039 RMSE: 0.138609 speed: 8147 dpps\n",
      "0.136 RMSE: 0.127214 speed: 8253 dpps\n",
      "0.233 RMSE: 0.128625 speed: 8231 dpps\n",
      "0.329 RMSE: 0.124665 speed: 8248 dpps\n",
      "0.426 RMSE: 0.128319 speed: 8162 dpps\n",
      "0.523 RMSE: 0.137465 speed: 8242 dpps\n",
      "0.620 RMSE: 0.137309 speed: 8256 dpps\n",
      "0.717 RMSE: 0.141336 speed: 8237 dpps\n",
      "0.814 RMSE: 0.138321 speed: 8255 dpps\n",
      "0.911 RMSE: 0.138028 speed: 8236 dpps\n",
      "Epoch: 13 Train RMSE: 0.137485\n",
      "0.039 RMSE: 0.157220 speed: 11149 dpps\n",
      "0.136 RMSE: 0.136285 speed: 14642 dpps\n",
      "0.233 RMSE: 0.134555 speed: 15515 dpps\n",
      "0.329 RMSE: 0.130563 speed: 16083 dpps\n",
      "0.426 RMSE: 0.133482 speed: 15911 dpps\n",
      "0.523 RMSE: 0.136580 speed: 16123 dpps\n",
      "0.620 RMSE: 0.136996 speed: 15832 dpps\n",
      "0.717 RMSE: 0.136366 speed: 15847 dpps\n",
      "0.814 RMSE: 0.136735 speed: 15962 dpps\n",
      "0.911 RMSE: 0.140334 speed: 16078 dpps\n",
      "Saving data to file\n",
      "Epoch: 13 Valid RMSE: 0.138160\n",
      "Epoch: 14 Learning rate: 0.663420\n",
      "0.039 RMSE: 0.137371 speed: 7419 dpps\n",
      "0.136 RMSE: 0.174196 speed: 7910 dpps\n",
      "0.233 RMSE: 0.153250 speed: 8128 dpps\n",
      "0.329 RMSE: 0.156832 speed: 8213 dpps\n",
      "0.426 RMSE: 0.151789 speed: 8222 dpps\n",
      "0.523 RMSE: 0.155867 speed: 8208 dpps\n",
      "0.620 RMSE: 0.151318 speed: 8224 dpps\n",
      "0.717 RMSE: 0.147455 speed: 8224 dpps\n",
      "0.814 RMSE: 0.146553 speed: 8259 dpps\n",
      "0.911 RMSE: 0.143036 speed: 8275 dpps\n",
      "Epoch: 14 Train RMSE: 0.142568\n",
      "0.039 RMSE: 0.107678 speed: 10316 dpps\n",
      "0.136 RMSE: 0.116483 speed: 12993 dpps\n",
      "0.233 RMSE: 0.126845 speed: 14656 dpps\n",
      "0.329 RMSE: 0.124973 speed: 15199 dpps\n",
      "0.426 RMSE: 0.129661 speed: 15565 dpps\n",
      "0.523 RMSE: 0.130952 speed: 15757 dpps\n",
      "0.620 RMSE: 0.130437 speed: 15901 dpps\n",
      "0.717 RMSE: 0.129214 speed: 15901 dpps\n",
      "0.814 RMSE: 0.125804 speed: 16028 dpps\n",
      "0.911 RMSE: 0.128571 speed: 16135 dpps\n",
      "Saving data to file\n",
      "Epoch: 14 Valid RMSE: 0.129677\n",
      "Epoch: 15 Learning rate: 0.630249\n",
      "0.039 RMSE: 0.133921 speed: 7912 dpps\n",
      "0.136 RMSE: 0.131488 speed: 8298 dpps\n",
      "0.233 RMSE: 0.132016 speed: 8212 dpps\n",
      "0.329 RMSE: 0.134425 speed: 8224 dpps\n",
      "0.426 RMSE: 0.136766 speed: 8236 dpps\n",
      "0.523 RMSE: 0.134070 speed: 8201 dpps\n",
      "0.620 RMSE: 0.137045 speed: 8243 dpps\n",
      "0.717 RMSE: 0.135234 speed: 8206 dpps\n",
      "0.814 RMSE: 0.134983 speed: 8203 dpps\n",
      "0.911 RMSE: 0.133302 speed: 8171 dpps\n",
      "Epoch: 15 Train RMSE: 0.132052\n",
      "0.039 RMSE: 0.140416 speed: 9870 dpps\n",
      "0.136 RMSE: 0.129483 speed: 13590 dpps\n",
      "0.233 RMSE: 0.135323 speed: 15288 dpps\n",
      "0.329 RMSE: 0.138601 speed: 15820 dpps\n",
      "0.426 RMSE: 0.136860 speed: 15881 dpps\n",
      "0.523 RMSE: 0.138797 speed: 15571 dpps\n",
      "0.620 RMSE: 0.137283 speed: 15888 dpps\n",
      "0.717 RMSE: 0.137709 speed: 16160 dpps\n",
      "0.814 RMSE: 0.137295 speed: 16267 dpps\n",
      "0.911 RMSE: 0.140053 speed: 16240 dpps\n",
      "Saving data to file\n",
      "Epoch: 15 Valid RMSE: 0.138836\n",
      "Epoch: 16 Learning rate: 0.598737\n",
      "0.039 RMSE: 0.138265 speed: 8599 dpps\n",
      "0.136 RMSE: 0.121042 speed: 8338 dpps\n",
      "0.233 RMSE: 0.134727 speed: 8232 dpps\n",
      "0.329 RMSE: 0.134117 speed: 8188 dpps\n",
      "0.426 RMSE: 0.131276 speed: 8254 dpps\n",
      "0.523 RMSE: 0.130939 speed: 8181 dpps\n",
      "0.620 RMSE: 0.133933 speed: 8202 dpps\n",
      "0.717 RMSE: 0.132631 speed: 8198 dpps\n",
      "0.814 RMSE: 0.130366 speed: 8221 dpps\n",
      "0.911 RMSE: 0.130256 speed: 8235 dpps\n",
      "Epoch: 16 Train RMSE: 0.130420\n",
      "0.039 RMSE: 0.125402 speed: 10278 dpps\n",
      "0.136 RMSE: 0.128955 speed: 13651 dpps\n",
      "0.233 RMSE: 0.132463 speed: 14419 dpps\n",
      "0.329 RMSE: 0.127084 speed: 15153 dpps\n",
      "0.426 RMSE: 0.123853 speed: 15206 dpps\n",
      "0.523 RMSE: 0.122180 speed: 15304 dpps\n",
      "0.620 RMSE: 0.124718 speed: 15308 dpps\n",
      "0.717 RMSE: 0.123261 speed: 15544 dpps\n",
      "0.814 RMSE: 0.125613 speed: 15362 dpps\n",
      "0.911 RMSE: 0.127199 speed: 15437 dpps\n",
      "Saving data to file\n",
      "Epoch: 16 Valid RMSE: 0.126902\n",
      "Epoch: 17 Learning rate: 0.568800\n",
      "0.039 RMSE: 0.119901 speed: 7981 dpps\n",
      "0.136 RMSE: 0.134389 speed: 8050 dpps\n",
      "0.233 RMSE: 0.139397 speed: 7954 dpps\n",
      "0.329 RMSE: 0.136982 speed: 7901 dpps\n",
      "0.426 RMSE: 0.134474 speed: 7981 dpps\n",
      "0.523 RMSE: 0.132820 speed: 8029 dpps\n",
      "0.620 RMSE: 0.130885 speed: 8034 dpps\n",
      "0.717 RMSE: 0.131081 speed: 8146 dpps\n",
      "0.814 RMSE: 0.130916 speed: 8195 dpps\n",
      "0.911 RMSE: 0.130428 speed: 8200 dpps\n",
      "Epoch: 17 Train RMSE: 0.129410\n",
      "0.039 RMSE: 0.174799 speed: 10360 dpps\n",
      "0.136 RMSE: 0.169078 speed: 13994 dpps\n",
      "0.233 RMSE: 0.158280 speed: 15115 dpps\n",
      "0.329 RMSE: 0.151095 speed: 15383 dpps\n",
      "0.426 RMSE: 0.151336 speed: 15438 dpps\n",
      "0.523 RMSE: 0.149917 speed: 15764 dpps\n",
      "0.620 RMSE: 0.144801 speed: 15921 dpps\n",
      "0.717 RMSE: 0.142152 speed: 15985 dpps\n",
      "0.814 RMSE: 0.137929 speed: 15969 dpps\n",
      "0.911 RMSE: 0.138283 speed: 15877 dpps\n",
      "Saving data to file\n",
      "Epoch: 17 Valid RMSE: 0.138960\n",
      "Epoch: 18 Learning rate: 0.540360\n",
      "0.039 RMSE: 0.124631 speed: 8127 dpps\n",
      "0.136 RMSE: 0.133776 speed: 8290 dpps\n",
      "0.233 RMSE: 0.131505 speed: 8345 dpps\n",
      "0.329 RMSE: 0.134628 speed: 8222 dpps\n",
      "0.426 RMSE: 0.130467 speed: 8188 dpps\n",
      "0.523 RMSE: 0.135196 speed: 8173 dpps\n",
      "0.620 RMSE: 0.137878 speed: 8101 dpps\n",
      "0.717 RMSE: 0.136762 speed: 8092 dpps\n",
      "0.814 RMSE: 0.135107 speed: 8167 dpps\n",
      "0.911 RMSE: 0.133419 speed: 8217 dpps\n",
      "Epoch: 18 Train RMSE: 0.133940\n",
      "0.039 RMSE: 0.135934 speed: 10711 dpps\n",
      "0.136 RMSE: 0.135844 speed: 14143 dpps\n",
      "0.233 RMSE: 0.134071 speed: 15089 dpps\n",
      "0.329 RMSE: 0.136030 speed: 15137 dpps\n",
      "0.426 RMSE: 0.133934 speed: 15156 dpps\n",
      "0.523 RMSE: 0.133208 speed: 14865 dpps\n",
      "0.620 RMSE: 0.131720 speed: 15051 dpps\n",
      "0.717 RMSE: 0.132414 speed: 15036 dpps\n",
      "0.814 RMSE: 0.130736 speed: 15095 dpps\n",
      "0.911 RMSE: 0.137266 speed: 15000 dpps\n",
      "Saving data to file\n",
      "Epoch: 18 Valid RMSE: 0.136995\n",
      "Epoch: 19 Learning rate: 0.513342\n",
      "0.039 RMSE: 0.124880 speed: 8942 dpps\n",
      "0.136 RMSE: 0.135695 speed: 8663 dpps\n",
      "0.233 RMSE: 0.132835 speed: 8683 dpps\n",
      "0.329 RMSE: 0.130128 speed: 8506 dpps\n",
      "0.426 RMSE: 0.128987 speed: 8495 dpps\n",
      "0.523 RMSE: 0.129497 speed: 8427 dpps\n",
      "0.620 RMSE: 0.132288 speed: 8467 dpps\n",
      "0.717 RMSE: 0.132600 speed: 8451 dpps\n",
      "0.814 RMSE: 0.133639 speed: 8415 dpps\n",
      "0.911 RMSE: 0.134374 speed: 8387 dpps\n",
      "Epoch: 19 Train RMSE: 0.134124\n",
      "0.039 RMSE: 0.131580 speed: 10411 dpps\n",
      "0.136 RMSE: 0.128236 speed: 13536 dpps\n",
      "0.233 RMSE: 0.135769 speed: 14252 dpps\n",
      "0.329 RMSE: 0.131890 speed: 15052 dpps\n",
      "0.426 RMSE: 0.127310 speed: 15287 dpps\n",
      "0.523 RMSE: 0.125892 speed: 15636 dpps\n",
      "0.620 RMSE: 0.125469 speed: 15482 dpps\n",
      "0.717 RMSE: 0.126352 speed: 15599 dpps\n",
      "0.814 RMSE: 0.126111 speed: 15541 dpps\n",
      "0.911 RMSE: 0.127899 speed: 15680 dpps\n",
      "Saving data to file\n",
      "Epoch: 19 Valid RMSE: 0.128228\n",
      "Epoch: 20 Learning rate: 0.487675\n",
      "0.039 RMSE: 0.129112 speed: 7664 dpps\n",
      "0.136 RMSE: 0.141464 speed: 8013 dpps\n",
      "0.233 RMSE: 0.140767 speed: 8061 dpps\n",
      "0.329 RMSE: 0.140220 speed: 8179 dpps\n",
      "0.426 RMSE: 0.139582 speed: 8148 dpps\n",
      "0.523 RMSE: 0.138548 speed: 8188 dpps\n",
      "0.620 RMSE: 0.138671 speed: 8170 dpps\n",
      "0.717 RMSE: 0.137225 speed: 8112 dpps\n",
      "0.814 RMSE: 0.136951 speed: 8142 dpps\n",
      "0.911 RMSE: 0.135954 speed: 8181 dpps\n",
      "Epoch: 20 Train RMSE: 0.136126\n",
      "0.039 RMSE: 0.110570 speed: 10998 dpps\n",
      "0.136 RMSE: 0.126050 speed: 14490 dpps\n",
      "0.233 RMSE: 0.129395 speed: 15271 dpps\n",
      "0.329 RMSE: 0.130380 speed: 15062 dpps\n",
      "0.426 RMSE: 0.130617 speed: 15010 dpps\n",
      "0.523 RMSE: 0.129228 speed: 15285 dpps\n",
      "0.620 RMSE: 0.129601 speed: 15392 dpps\n",
      "0.717 RMSE: 0.129363 speed: 15520 dpps\n",
      "0.814 RMSE: 0.129937 speed: 15398 dpps\n",
      "0.911 RMSE: 0.130744 speed: 15434 dpps\n",
      "Saving data to file\n",
      "Epoch: 20 Valid RMSE: 0.135940\n",
      "Epoch: 21 Learning rate: 0.463291\n",
      "0.039 RMSE: 0.121026 speed: 8676 dpps\n",
      "0.136 RMSE: 0.140075 speed: 8595 dpps\n",
      "0.233 RMSE: 0.133593 speed: 8303 dpps\n",
      "0.329 RMSE: 0.132333 speed: 8294 dpps\n",
      "0.426 RMSE: 0.137204 speed: 8308 dpps\n",
      "0.523 RMSE: 0.136822 speed: 8307 dpps\n",
      "0.620 RMSE: 0.136198 speed: 8292 dpps\n",
      "0.717 RMSE: 0.135751 speed: 8292 dpps\n",
      "0.814 RMSE: 0.137837 speed: 8274 dpps\n",
      "0.911 RMSE: 0.136533 speed: 8257 dpps\n",
      "Epoch: 21 Train RMSE: 0.135199\n",
      "0.039 RMSE: 0.141414 speed: 10316 dpps\n",
      "0.136 RMSE: 0.142931 speed: 12833 dpps\n",
      "0.233 RMSE: 0.135685 speed: 14284 dpps\n",
      "0.329 RMSE: 0.141479 speed: 14785 dpps\n",
      "0.426 RMSE: 0.137331 speed: 15260 dpps\n",
      "0.523 RMSE: 0.135783 speed: 15474 dpps\n",
      "0.620 RMSE: 0.141292 speed: 15322 dpps\n",
      "0.717 RMSE: 0.140338 speed: 15219 dpps\n",
      "0.814 RMSE: 0.139068 speed: 15256 dpps\n",
      "0.911 RMSE: 0.138610 speed: 15117 dpps\n",
      "Saving data to file\n",
      "Epoch: 21 Valid RMSE: 0.138168\n",
      "Epoch: 22 Learning rate: 0.440127\n",
      "0.039 RMSE: 0.119852 speed: 7986 dpps\n",
      "0.136 RMSE: 0.135494 speed: 8003 dpps\n",
      "0.233 RMSE: 0.135050 speed: 8105 dpps\n",
      "0.329 RMSE: 0.130168 speed: 8195 dpps\n",
      "0.426 RMSE: 0.134125 speed: 8194 dpps\n",
      "0.523 RMSE: 0.132748 speed: 8249 dpps\n",
      "0.620 RMSE: 0.130282 speed: 8231 dpps\n",
      "0.717 RMSE: 0.128481 speed: 8279 dpps\n",
      "0.814 RMSE: 0.128649 speed: 8289 dpps\n",
      "0.911 RMSE: 0.129765 speed: 8322 dpps\n",
      "Epoch: 22 Train RMSE: 0.129257\n",
      "0.039 RMSE: 0.123932 speed: 10691 dpps\n",
      "0.136 RMSE: 0.129708 speed: 13560 dpps\n",
      "0.233 RMSE: 0.129693 speed: 15071 dpps\n",
      "0.329 RMSE: 0.128249 speed: 15049 dpps\n",
      "0.426 RMSE: 0.132129 speed: 15048 dpps\n",
      "0.523 RMSE: 0.133311 speed: 15125 dpps\n",
      "0.620 RMSE: 0.131085 speed: 14978 dpps\n",
      "0.717 RMSE: 0.132351 speed: 15217 dpps\n",
      "0.814 RMSE: 0.133370 speed: 15391 dpps\n",
      "0.911 RMSE: 0.132453 speed: 15672 dpps\n",
      "Saving data to file\n",
      "Epoch: 22 Valid RMSE: 0.132111\n",
      "Epoch: 23 Learning rate: 0.418120\n",
      "0.039 RMSE: 0.122338 speed: 8316 dpps\n",
      "0.136 RMSE: 0.153384 speed: 8303 dpps\n",
      "0.233 RMSE: 0.142761 speed: 8024 dpps\n",
      "0.329 RMSE: 0.133415 speed: 8065 dpps\n",
      "0.426 RMSE: 0.129900 speed: 8119 dpps\n",
      "0.523 RMSE: 0.132779 speed: 8101 dpps\n",
      "0.620 RMSE: 0.130209 speed: 8148 dpps\n",
      "0.717 RMSE: 0.129874 speed: 8148 dpps\n",
      "0.814 RMSE: 0.135646 speed: 8176 dpps\n",
      "0.911 RMSE: 0.136972 speed: 8163 dpps\n",
      "Epoch: 23 Train RMSE: 0.136262\n",
      "0.039 RMSE: 0.113572 speed: 10225 dpps\n",
      "0.136 RMSE: 0.136881 speed: 13427 dpps\n",
      "0.233 RMSE: 0.136064 speed: 14405 dpps\n",
      "0.329 RMSE: 0.132862 speed: 14881 dpps\n",
      "0.426 RMSE: 0.135001 speed: 14948 dpps\n",
      "0.523 RMSE: 0.130168 speed: 14612 dpps\n",
      "0.620 RMSE: 0.132048 speed: 14578 dpps\n",
      "0.717 RMSE: 0.132669 speed: 14624 dpps\n",
      "0.814 RMSE: 0.133578 speed: 14673 dpps\n",
      "0.911 RMSE: 0.135377 speed: 14833 dpps\n",
      "Saving data to file\n",
      "Epoch: 23 Valid RMSE: 0.134820\n",
      "Epoch: 24 Learning rate: 0.397214\n",
      "0.039 RMSE: 0.128323 speed: 8593 dpps\n",
      "0.136 RMSE: 0.133007 speed: 8509 dpps\n",
      "0.233 RMSE: 0.127880 speed: 8477 dpps\n",
      "0.329 RMSE: 0.128628 speed: 8301 dpps\n",
      "0.426 RMSE: 0.132026 speed: 8282 dpps\n",
      "0.523 RMSE: 0.136844 speed: 8219 dpps\n",
      "0.620 RMSE: 0.135249 speed: 8195 dpps\n",
      "0.717 RMSE: 0.136270 speed: 8224 dpps\n",
      "0.814 RMSE: 0.135394 speed: 8222 dpps\n",
      "0.911 RMSE: 0.133173 speed: 8247 dpps\n",
      "Epoch: 24 Train RMSE: 0.131799\n",
      "0.039 RMSE: 0.144312 speed: 11077 dpps\n",
      "0.136 RMSE: 0.164564 speed: 14210 dpps\n",
      "0.233 RMSE: 0.149425 speed: 15337 dpps\n",
      "0.329 RMSE: 0.146999 speed: 15743 dpps\n",
      "0.426 RMSE: 0.143172 speed: 16004 dpps\n",
      "0.523 RMSE: 0.136575 speed: 15793 dpps\n",
      "0.620 RMSE: 0.134394 speed: 15757 dpps\n",
      "0.717 RMSE: 0.135228 speed: 15788 dpps\n",
      "0.814 RMSE: 0.134969 speed: 16099 dpps\n",
      "0.911 RMSE: 0.134143 speed: 15847 dpps\n",
      "Saving data to file\n",
      "Epoch: 24 Valid RMSE: 0.133487\n",
      "Epoch: 25 Learning rate: 0.377354\n",
      "0.039 RMSE: 0.138497 speed: 7644 dpps\n",
      "0.136 RMSE: 0.139200 speed: 8344 dpps\n",
      "0.233 RMSE: 0.137686 speed: 8414 dpps\n",
      "0.329 RMSE: 0.135464 speed: 8385 dpps\n",
      "0.426 RMSE: 0.139754 speed: 8462 dpps\n",
      "0.523 RMSE: 0.137049 speed: 8315 dpps\n",
      "0.620 RMSE: 0.135121 speed: 8342 dpps\n",
      "0.717 RMSE: 0.135927 speed: 8359 dpps\n",
      "0.814 RMSE: 0.134345 speed: 8351 dpps\n",
      "0.911 RMSE: 0.133237 speed: 8375 dpps\n",
      "Epoch: 25 Train RMSE: 0.130818\n",
      "0.039 RMSE: 0.161282 speed: 10665 dpps\n",
      "0.136 RMSE: 0.143328 speed: 13778 dpps\n",
      "0.233 RMSE: 0.149441 speed: 14502 dpps\n",
      "0.329 RMSE: 0.144439 speed: 15394 dpps\n",
      "0.426 RMSE: 0.140167 speed: 15563 dpps\n",
      "0.523 RMSE: 0.139999 speed: 15908 dpps\n",
      "0.620 RMSE: 0.136964 speed: 15677 dpps\n",
      "0.717 RMSE: 0.135849 speed: 15489 dpps\n",
      "0.814 RMSE: 0.136719 speed: 15530 dpps\n",
      "0.911 RMSE: 0.138027 speed: 15663 dpps\n",
      "Saving data to file\n",
      "Epoch: 25 Valid RMSE: 0.135794\n",
      "Epoch: 26 Learning rate: 0.358486\n",
      "0.039 RMSE: 0.163006 speed: 7883 dpps\n",
      "0.136 RMSE: 0.145062 speed: 8366 dpps\n",
      "0.233 RMSE: 0.141901 speed: 8404 dpps\n",
      "0.329 RMSE: 0.137301 speed: 8446 dpps\n",
      "0.426 RMSE: 0.134277 speed: 8478 dpps\n",
      "0.523 RMSE: 0.138766 speed: 8373 dpps\n",
      "0.620 RMSE: 0.136189 speed: 8364 dpps\n",
      "0.717 RMSE: 0.136585 speed: 8349 dpps\n",
      "0.814 RMSE: 0.138630 speed: 8361 dpps\n",
      "0.911 RMSE: 0.137702 speed: 8366 dpps\n",
      "Epoch: 26 Train RMSE: 0.137865\n",
      "0.039 RMSE: 0.161100 speed: 8974 dpps\n",
      "0.136 RMSE: 0.135171 speed: 13648 dpps\n",
      "0.233 RMSE: 0.135814 speed: 14571 dpps\n",
      "0.329 RMSE: 0.131077 speed: 14762 dpps\n",
      "0.426 RMSE: 0.128249 speed: 15201 dpps\n",
      "0.523 RMSE: 0.125573 speed: 15430 dpps\n",
      "0.620 RMSE: 0.125563 speed: 15414 dpps\n",
      "0.717 RMSE: 0.127822 speed: 15686 dpps\n",
      "0.814 RMSE: 0.127576 speed: 15779 dpps\n",
      "0.911 RMSE: 0.127042 speed: 15672 dpps\n",
      "Saving data to file\n",
      "Epoch: 26 Valid RMSE: 0.126894\n",
      "Epoch: 27 Learning rate: 0.340562\n",
      "0.039 RMSE: 0.149350 speed: 7875 dpps\n",
      "0.136 RMSE: 0.137975 speed: 8020 dpps\n",
      "0.233 RMSE: 0.139997 speed: 8206 dpps\n",
      "0.329 RMSE: 0.137340 speed: 8235 dpps\n",
      "0.426 RMSE: 0.138155 speed: 8298 dpps\n",
      "0.523 RMSE: 0.136219 speed: 8243 dpps\n",
      "0.620 RMSE: 0.137886 speed: 8250 dpps\n",
      "0.717 RMSE: 0.137133 speed: 8204 dpps\n",
      "0.814 RMSE: 0.135501 speed: 8229 dpps\n",
      "0.911 RMSE: 0.133320 speed: 8235 dpps\n",
      "Epoch: 27 Train RMSE: 0.132253\n",
      "0.039 RMSE: 0.110581 speed: 10769 dpps\n",
      "0.136 RMSE: 0.123288 speed: 14681 dpps\n",
      "0.233 RMSE: 0.128924 speed: 14805 dpps\n",
      "0.329 RMSE: 0.127465 speed: 14816 dpps\n",
      "0.426 RMSE: 0.132446 speed: 15191 dpps\n",
      "0.523 RMSE: 0.130330 speed: 15424 dpps\n",
      "0.620 RMSE: 0.130283 speed: 15696 dpps\n",
      "0.717 RMSE: 0.127264 speed: 15974 dpps\n",
      "0.814 RMSE: 0.126723 speed: 16118 dpps\n",
      "0.911 RMSE: 0.130130 speed: 16187 dpps\n",
      "Saving data to file\n",
      "Epoch: 27 Valid RMSE: 0.128398\n",
      "Epoch: 28 Learning rate: 0.323534\n",
      "0.039 RMSE: 0.108353 speed: 7155 dpps\n",
      "0.136 RMSE: 0.118389 speed: 7892 dpps\n",
      "0.233 RMSE: 0.127191 speed: 8128 dpps\n",
      "0.329 RMSE: 0.126940 speed: 8225 dpps\n",
      "0.426 RMSE: 0.132459 speed: 8200 dpps\n",
      "0.523 RMSE: 0.129699 speed: 8217 dpps\n",
      "0.620 RMSE: 0.131235 speed: 8203 dpps\n",
      "0.717 RMSE: 0.130510 speed: 8234 dpps\n",
      "0.814 RMSE: 0.133326 speed: 8229 dpps\n",
      "0.911 RMSE: 0.131876 speed: 8256 dpps\n",
      "Epoch: 28 Train RMSE: 0.135241\n",
      "0.039 RMSE: 0.125935 speed: 8678 dpps\n",
      "0.136 RMSE: 0.131546 speed: 13310 dpps\n",
      "0.233 RMSE: 0.139878 speed: 13678 dpps\n",
      "0.329 RMSE: 0.132532 speed: 14081 dpps\n",
      "0.426 RMSE: 0.133733 speed: 14687 dpps\n",
      "0.523 RMSE: 0.137629 speed: 15137 dpps\n",
      "0.620 RMSE: 0.135199 speed: 15021 dpps\n",
      "0.717 RMSE: 0.137367 speed: 15146 dpps\n",
      "0.814 RMSE: 0.136012 speed: 15173 dpps\n",
      "0.911 RMSE: 0.135311 speed: 15189 dpps\n",
      "Saving data to file\n",
      "Epoch: 28 Valid RMSE: 0.135897\n",
      "Epoch: 29 Learning rate: 0.307357\n",
      "0.039 RMSE: 0.163019 speed: 8006 dpps\n",
      "0.136 RMSE: 0.154617 speed: 8351 dpps\n",
      "0.233 RMSE: 0.150951 speed: 8175 dpps\n",
      "0.329 RMSE: 0.146470 speed: 8183 dpps\n",
      "0.426 RMSE: 0.142648 speed: 8192 dpps\n",
      "0.523 RMSE: 0.139386 speed: 8178 dpps\n",
      "0.620 RMSE: 0.137906 speed: 8204 dpps\n",
      "0.717 RMSE: 0.136986 speed: 8204 dpps\n",
      "0.814 RMSE: 0.136789 speed: 8246 dpps\n",
      "0.911 RMSE: 0.136041 speed: 8251 dpps\n",
      "Epoch: 29 Train RMSE: 0.135473\n",
      "0.039 RMSE: 0.121812 speed: 10623 dpps\n",
      "0.136 RMSE: 0.121883 speed: 14530 dpps\n",
      "0.233 RMSE: 0.123818 speed: 15163 dpps\n",
      "0.329 RMSE: 0.124912 speed: 15498 dpps\n",
      "0.426 RMSE: 0.128905 speed: 15387 dpps\n",
      "0.523 RMSE: 0.130933 speed: 15118 dpps\n",
      "0.620 RMSE: 0.129595 speed: 15368 dpps\n",
      "0.717 RMSE: 0.129179 speed: 15499 dpps\n",
      "0.814 RMSE: 0.128528 speed: 15675 dpps\n",
      "0.911 RMSE: 0.128145 speed: 15790 dpps\n",
      "Saving data to file\n",
      "Epoch: 29 Valid RMSE: 0.128280\n",
      "Epoch: 30 Learning rate: 0.291989\n",
      "0.039 RMSE: 0.099076 speed: 8848 dpps\n",
      "0.136 RMSE: 0.107574 speed: 8536 dpps\n",
      "0.233 RMSE: 0.115840 speed: 8227 dpps\n",
      "0.329 RMSE: 0.117742 speed: 8136 dpps\n",
      "0.426 RMSE: 0.115462 speed: 8113 dpps\n",
      "0.523 RMSE: 0.116764 speed: 8107 dpps\n",
      "0.620 RMSE: 0.116198 speed: 8116 dpps\n",
      "0.717 RMSE: 0.117226 speed: 8117 dpps\n",
      "0.814 RMSE: 0.123133 speed: 8117 dpps\n",
      "0.911 RMSE: 0.124451 speed: 8133 dpps\n",
      "Epoch: 30 Train RMSE: 0.124894\n",
      "0.039 RMSE: 0.121420 speed: 10747 dpps\n",
      "0.136 RMSE: 0.136219 speed: 14421 dpps\n",
      "0.233 RMSE: 0.132764 speed: 15252 dpps\n",
      "0.329 RMSE: 0.135467 speed: 15592 dpps\n",
      "0.426 RMSE: 0.135051 speed: 15736 dpps\n",
      "0.523 RMSE: 0.131784 speed: 15921 dpps\n",
      "0.620 RMSE: 0.131287 speed: 16069 dpps\n",
      "0.717 RMSE: 0.136135 speed: 16081 dpps\n",
      "0.814 RMSE: 0.134259 speed: 15996 dpps\n",
      "0.911 RMSE: 0.133292 speed: 15991 dpps\n",
      "Saving data to file\n",
      "Epoch: 30 Valid RMSE: 0.133647\n",
      "Epoch: 31 Learning rate: 0.277390\n",
      "0.039 RMSE: 0.107415 speed: 8535 dpps\n",
      "0.136 RMSE: 0.122834 speed: 8679 dpps\n",
      "0.233 RMSE: 0.127789 speed: 8621 dpps\n",
      "0.329 RMSE: 0.128430 speed: 8513 dpps\n",
      "0.426 RMSE: 0.128663 speed: 8424 dpps\n",
      "0.523 RMSE: 0.128432 speed: 8408 dpps\n",
      "0.620 RMSE: 0.129485 speed: 8402 dpps\n",
      "0.717 RMSE: 0.128196 speed: 8374 dpps\n",
      "0.814 RMSE: 0.128711 speed: 8360 dpps\n",
      "0.911 RMSE: 0.129993 speed: 8300 dpps\n",
      "Epoch: 31 Train RMSE: 0.130202\n",
      "0.039 RMSE: 0.123460 speed: 11248 dpps\n",
      "0.136 RMSE: 0.167099 speed: 14380 dpps\n",
      "0.233 RMSE: 0.163464 speed: 15287 dpps\n",
      "0.329 RMSE: 0.153414 speed: 15970 dpps\n",
      "0.426 RMSE: 0.147811 speed: 16307 dpps\n",
      "0.523 RMSE: 0.143603 speed: 16142 dpps\n",
      "0.620 RMSE: 0.141549 speed: 16028 dpps\n",
      "0.717 RMSE: 0.139456 speed: 15922 dpps\n",
      "0.814 RMSE: 0.137622 speed: 16203 dpps\n",
      "0.911 RMSE: 0.136356 speed: 16359 dpps\n",
      "Saving data to file\n",
      "Epoch: 31 Valid RMSE: 0.136220\n",
      "Epoch: 32 Learning rate: 0.263520\n",
      "0.039 RMSE: 0.133641 speed: 8243 dpps\n",
      "0.136 RMSE: 0.140918 speed: 8095 dpps\n",
      "0.233 RMSE: 0.132856 speed: 8175 dpps\n",
      "0.329 RMSE: 0.137158 speed: 8183 dpps\n",
      "0.426 RMSE: 0.135651 speed: 8249 dpps\n",
      "0.523 RMSE: 0.138337 speed: 8209 dpps\n",
      "0.620 RMSE: 0.136411 speed: 8176 dpps\n",
      "0.717 RMSE: 0.133575 speed: 8195 dpps\n",
      "0.814 RMSE: 0.132058 speed: 8182 dpps\n",
      "0.911 RMSE: 0.131659 speed: 8212 dpps\n",
      "Epoch: 32 Train RMSE: 0.131414\n",
      "0.039 RMSE: 0.129585 speed: 8990 dpps\n",
      "0.136 RMSE: 0.124894 speed: 12628 dpps\n",
      "0.233 RMSE: 0.136546 speed: 13351 dpps\n",
      "0.329 RMSE: 0.129787 speed: 13940 dpps\n",
      "0.426 RMSE: 0.129236 speed: 14231 dpps\n",
      "0.523 RMSE: 0.134073 speed: 14485 dpps\n",
      "0.620 RMSE: 0.131891 speed: 14788 dpps\n",
      "0.717 RMSE: 0.130237 speed: 14847 dpps\n",
      "0.814 RMSE: 0.129994 speed: 14827 dpps\n",
      "0.911 RMSE: 0.130885 speed: 14840 dpps\n",
      "Saving data to file\n",
      "Epoch: 32 Valid RMSE: 0.129595\n",
      "Epoch: 33 Learning rate: 0.250344\n",
      "0.039 RMSE: 0.115769 speed: 7662 dpps\n",
      "0.136 RMSE: 0.116984 speed: 8208 dpps\n",
      "0.233 RMSE: 0.120625 speed: 8291 dpps\n",
      "0.329 RMSE: 0.126316 speed: 8232 dpps\n",
      "0.426 RMSE: 0.133276 speed: 8228 dpps\n",
      "0.523 RMSE: 0.135473 speed: 8277 dpps\n",
      "0.620 RMSE: 0.134841 speed: 8330 dpps\n",
      "0.717 RMSE: 0.134370 speed: 8348 dpps\n",
      "0.814 RMSE: 0.132872 speed: 8310 dpps\n",
      "0.911 RMSE: 0.132193 speed: 8353 dpps\n",
      "Epoch: 33 Train RMSE: 0.132504\n",
      "0.039 RMSE: 0.175486 speed: 10856 dpps\n",
      "0.136 RMSE: 0.142453 speed: 12985 dpps\n",
      "0.233 RMSE: 0.134187 speed: 14273 dpps\n",
      "0.329 RMSE: 0.134934 speed: 14336 dpps\n",
      "0.426 RMSE: 0.136465 speed: 14778 dpps\n",
      "0.523 RMSE: 0.134391 speed: 14848 dpps\n",
      "0.620 RMSE: 0.135330 speed: 14683 dpps\n",
      "0.717 RMSE: 0.134401 speed: 14971 dpps\n",
      "0.814 RMSE: 0.133757 speed: 15154 dpps\n",
      "0.911 RMSE: 0.135361 speed: 15259 dpps\n",
      "Saving data to file\n",
      "Epoch: 33 Valid RMSE: 0.136679\n",
      "Epoch: 34 Learning rate: 0.237827\n",
      "0.039 RMSE: 0.142790 speed: 8560 dpps\n",
      "0.136 RMSE: 0.129099 speed: 8282 dpps\n",
      "0.233 RMSE: 0.129854 speed: 8413 dpps\n",
      "0.329 RMSE: 0.128691 speed: 8340 dpps\n",
      "0.426 RMSE: 0.127404 speed: 8332 dpps\n",
      "0.523 RMSE: 0.125557 speed: 8379 dpps\n",
      "0.620 RMSE: 0.124539 speed: 8338 dpps\n",
      "0.717 RMSE: 0.123696 speed: 8320 dpps\n",
      "0.814 RMSE: 0.123213 speed: 8277 dpps\n",
      "0.911 RMSE: 0.122970 speed: 8242 dpps\n",
      "Epoch: 34 Train RMSE: 0.124393\n",
      "0.039 RMSE: 0.113499 speed: 9540 dpps\n",
      "0.136 RMSE: 0.113426 speed: 13856 dpps\n",
      "0.233 RMSE: 0.127175 speed: 14581 dpps\n",
      "0.329 RMSE: 0.131941 speed: 15378 dpps\n",
      "0.426 RMSE: 0.136285 speed: 15235 dpps\n",
      "0.523 RMSE: 0.134770 speed: 15348 dpps\n",
      "0.620 RMSE: 0.138358 speed: 15409 dpps\n",
      "0.717 RMSE: 0.137321 speed: 15473 dpps\n",
      "0.814 RMSE: 0.136488 speed: 15389 dpps\n",
      "0.911 RMSE: 0.136661 speed: 15576 dpps\n",
      "Saving data to file\n",
      "Epoch: 34 Valid RMSE: 0.140400\n",
      "Epoch: 35 Learning rate: 0.225936\n",
      "0.039 RMSE: 0.130241 speed: 8325 dpps\n",
      "0.136 RMSE: 0.137732 speed: 8384 dpps\n",
      "0.233 RMSE: 0.144417 speed: 8190 dpps\n",
      "0.329 RMSE: 0.137890 speed: 8172 dpps\n",
      "0.426 RMSE: 0.137343 speed: 8190 dpps\n",
      "0.523 RMSE: 0.134672 speed: 8183 dpps\n",
      "0.620 RMSE: 0.133921 speed: 8233 dpps\n",
      "0.717 RMSE: 0.133218 speed: 8190 dpps\n",
      "0.814 RMSE: 0.132230 speed: 8204 dpps\n",
      "0.911 RMSE: 0.131363 speed: 8224 dpps\n",
      "Epoch: 35 Train RMSE: 0.132150\n",
      "0.039 RMSE: 0.148685 speed: 10211 dpps\n",
      "0.136 RMSE: 0.140420 speed: 13899 dpps\n",
      "0.233 RMSE: 0.135165 speed: 14914 dpps\n",
      "0.329 RMSE: 0.131198 speed: 15277 dpps\n",
      "0.426 RMSE: 0.136950 speed: 15166 dpps\n",
      "0.523 RMSE: 0.136697 speed: 15211 dpps\n",
      "0.620 RMSE: 0.136084 speed: 15507 dpps\n",
      "0.717 RMSE: 0.134479 speed: 15594 dpps\n",
      "0.814 RMSE: 0.131570 speed: 15606 dpps\n",
      "0.911 RMSE: 0.132117 speed: 15675 dpps\n",
      "Saving data to file\n",
      "Epoch: 35 Valid RMSE: 0.133172\n",
      "Epoch: 36 Learning rate: 0.214639\n",
      "0.039 RMSE: 0.137643 speed: 7996 dpps\n",
      "0.136 RMSE: 0.131772 speed: 8123 dpps\n",
      "0.233 RMSE: 0.126621 speed: 8171 dpps\n",
      "0.329 RMSE: 0.127280 speed: 8149 dpps\n",
      "0.426 RMSE: 0.128555 speed: 8221 dpps\n",
      "0.523 RMSE: 0.127557 speed: 8195 dpps\n",
      "0.620 RMSE: 0.125824 speed: 8207 dpps\n",
      "0.717 RMSE: 0.127093 speed: 8235 dpps\n",
      "0.814 RMSE: 0.128222 speed: 8267 dpps\n",
      "0.911 RMSE: 0.131085 speed: 8262 dpps\n",
      "Epoch: 36 Train RMSE: 0.131463\n",
      "0.039 RMSE: 0.107306 speed: 10454 dpps\n",
      "0.136 RMSE: 0.153924 speed: 13161 dpps\n",
      "0.233 RMSE: 0.144491 speed: 14566 dpps\n",
      "0.329 RMSE: 0.140687 speed: 15338 dpps\n",
      "0.426 RMSE: 0.136429 speed: 15457 dpps\n",
      "0.523 RMSE: 0.138176 speed: 15467 dpps\n",
      "0.620 RMSE: 0.137610 speed: 15772 dpps\n",
      "0.717 RMSE: 0.137554 speed: 15735 dpps\n",
      "0.814 RMSE: 0.140744 speed: 15917 dpps\n",
      "0.911 RMSE: 0.139373 speed: 15738 dpps\n",
      "Saving data to file\n",
      "Epoch: 36 Valid RMSE: 0.135980\n",
      "Epoch: 37 Learning rate: 0.203907\n",
      "0.039 RMSE: 0.131742 speed: 8022 dpps\n",
      "0.136 RMSE: 0.132582 speed: 8441 dpps\n",
      "0.233 RMSE: 0.126621 speed: 8338 dpps\n",
      "0.329 RMSE: 0.127976 speed: 8285 dpps\n",
      "0.426 RMSE: 0.130955 speed: 8328 dpps\n",
      "0.523 RMSE: 0.128746 speed: 8347 dpps\n",
      "0.620 RMSE: 0.134872 speed: 8320 dpps\n",
      "0.717 RMSE: 0.134478 speed: 8325 dpps\n",
      "0.814 RMSE: 0.134348 speed: 8320 dpps\n",
      "0.911 RMSE: 0.133197 speed: 8294 dpps\n",
      "Epoch: 37 Train RMSE: 0.133851\n",
      "0.039 RMSE: 0.182892 speed: 10281 dpps\n",
      "0.136 RMSE: 0.158049 speed: 12837 dpps\n",
      "0.233 RMSE: 0.152291 speed: 13414 dpps\n",
      "0.329 RMSE: 0.144950 speed: 13586 dpps\n",
      "0.426 RMSE: 0.148006 speed: 14338 dpps\n",
      "0.523 RMSE: 0.142784 speed: 14603 dpps\n",
      "0.620 RMSE: 0.138818 speed: 14998 dpps\n",
      "0.717 RMSE: 0.135076 speed: 15073 dpps\n",
      "0.814 RMSE: 0.134294 speed: 15124 dpps\n",
      "0.911 RMSE: 0.133361 speed: 15290 dpps\n",
      "Saving data to file\n",
      "Epoch: 37 Valid RMSE: 0.133463\n",
      "Epoch: 38 Learning rate: 0.193711\n",
      "0.039 RMSE: 0.122875 speed: 7483 dpps\n",
      "0.136 RMSE: 0.135016 speed: 8130 dpps\n",
      "0.233 RMSE: 0.137574 speed: 8218 dpps\n",
      "0.329 RMSE: 0.130044 speed: 8298 dpps\n",
      "0.426 RMSE: 0.135253 speed: 8270 dpps\n",
      "0.523 RMSE: 0.134960 speed: 8241 dpps\n",
      "0.620 RMSE: 0.135408 speed: 8218 dpps\n",
      "0.717 RMSE: 0.135027 speed: 8172 dpps\n",
      "0.814 RMSE: 0.135189 speed: 8186 dpps\n",
      "0.911 RMSE: 0.133594 speed: 8218 dpps\n",
      "Epoch: 38 Train RMSE: 0.133523\n",
      "0.039 RMSE: 0.105871 speed: 10156 dpps\n",
      "0.136 RMSE: 0.130953 speed: 14066 dpps\n",
      "0.233 RMSE: 0.128972 speed: 14221 dpps\n",
      "0.329 RMSE: 0.131958 speed: 14647 dpps\n",
      "0.426 RMSE: 0.132584 speed: 14635 dpps\n",
      "0.523 RMSE: 0.131286 speed: 14860 dpps\n",
      "0.620 RMSE: 0.130247 speed: 15081 dpps\n",
      "0.717 RMSE: 0.128083 speed: 15277 dpps\n",
      "0.814 RMSE: 0.130641 speed: 15216 dpps\n",
      "0.911 RMSE: 0.132606 speed: 15093 dpps\n",
      "Saving data to file\n",
      "Epoch: 38 Valid RMSE: 0.130968\n",
      "Epoch: 39 Learning rate: 0.184026\n",
      "0.039 RMSE: 0.135783 speed: 8081 dpps\n",
      "0.136 RMSE: 0.111900 speed: 8026 dpps\n",
      "0.233 RMSE: 0.118301 speed: 8020 dpps\n",
      "0.329 RMSE: 0.125711 speed: 8002 dpps\n",
      "0.426 RMSE: 0.128718 speed: 8003 dpps\n",
      "0.523 RMSE: 0.131638 speed: 7979 dpps\n",
      "0.620 RMSE: 0.131066 speed: 8034 dpps\n",
      "0.717 RMSE: 0.129643 speed: 8043 dpps\n",
      "0.814 RMSE: 0.128905 speed: 8030 dpps\n",
      "0.911 RMSE: 0.127400 speed: 8072 dpps\n",
      "Epoch: 39 Train RMSE: 0.126681\n",
      "0.039 RMSE: 0.135745 speed: 10527 dpps\n",
      "0.136 RMSE: 0.140548 speed: 13628 dpps\n",
      "0.233 RMSE: 0.154098 speed: 14334 dpps\n",
      "0.329 RMSE: 0.148274 speed: 14590 dpps\n",
      "0.426 RMSE: 0.142378 speed: 14959 dpps\n",
      "0.523 RMSE: 0.139437 speed: 15097 dpps\n",
      "0.620 RMSE: 0.140175 speed: 15412 dpps\n",
      "0.717 RMSE: 0.142202 speed: 15532 dpps\n",
      "0.814 RMSE: 0.139871 speed: 15476 dpps\n",
      "0.911 RMSE: 0.140123 speed: 15313 dpps\n",
      "Saving data to file\n",
      "Epoch: 39 Valid RMSE: 0.139916\n",
      "Epoch: 40 Learning rate: 0.174825\n",
      "0.039 RMSE: 0.122303 speed: 7803 dpps\n",
      "0.136 RMSE: 0.129938 speed: 8023 dpps\n",
      "0.233 RMSE: 0.129921 speed: 8201 dpps\n",
      "0.329 RMSE: 0.135559 speed: 8223 dpps\n",
      "0.426 RMSE: 0.139537 speed: 8223 dpps\n",
      "0.523 RMSE: 0.139683 speed: 8164 dpps\n",
      "0.620 RMSE: 0.138156 speed: 8166 dpps\n",
      "0.717 RMSE: 0.139144 speed: 8195 dpps\n",
      "0.814 RMSE: 0.136747 speed: 8186 dpps\n",
      "0.911 RMSE: 0.138458 speed: 8206 dpps\n",
      "Epoch: 40 Train RMSE: 0.138711\n",
      "0.039 RMSE: 0.141277 speed: 9198 dpps\n",
      "0.136 RMSE: 0.144953 speed: 11847 dpps\n",
      "0.233 RMSE: 0.137252 speed: 13410 dpps\n",
      "0.329 RMSE: 0.143643 speed: 14185 dpps\n",
      "0.426 RMSE: 0.142527 speed: 14417 dpps\n",
      "0.523 RMSE: 0.137714 speed: 14304 dpps\n",
      "0.620 RMSE: 0.138503 speed: 14857 dpps\n",
      "0.717 RMSE: 0.138061 speed: 14942 dpps\n",
      "0.814 RMSE: 0.136670 speed: 15101 dpps\n",
      "0.911 RMSE: 0.136664 speed: 15112 dpps\n",
      "Saving data to file\n",
      "Epoch: 40 Valid RMSE: 0.136468\n",
      "Saving data to file\n",
      "Test RMSE: 0.4365\n"
     ]
    }
   ],
   "source": [
    "\"\"\"A Contextual LSTM for prediction on the Endomondo Exercise Dataset\n",
    "\n",
    "\n",
    "The hyperparameters used in the model:\n",
    "- init_scale - the initial scale of the weights\n",
    "- learning_rate - the initial value of the learning rate\n",
    "- max_grad_norm - the maximum permissible norm of the gradient\n",
    "- num_layers - the number of LSTM layers\n",
    "- num_steps - the number of unrolled steps of LSTM\n",
    "- hidden_size - the number of LSTM units\n",
    "- max_epoch - the number of epochs trained with the initial learning rate\n",
    "- max_max_epoch - the total number of epochs for training\n",
    "- keep_prob - the probability of keeping weights in the dropout layer\n",
    "- lr_decay - the decay of the learning rate for each epoch after \"max_epoch\"\n",
    "- batch_size - the batch size\n",
    "\n",
    "\n",
    "To run:\n",
    "\n",
    "$ python Endomondo_RNN_tests.py --data_path=simple-examples/data/\n",
    "\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "# from tensorflow.models.rnn.ptb import reader\n",
    "# from tensorflow.models.rnn import *\n",
    "#from dataInterpreter_Endomondo_fixedInputs import dataInterpreter, metaDataEndomondo\n",
    "from data_interpreter_with_excision import dataInterpreter, metaDataEndomondo\n",
    "from inputManager import inputManager\n",
    "\n",
    "# flags = tf.flags\n",
    "logging = tf.logging\n",
    "\n",
    "# flags.DEFINE_string(\n",
    "#    \"model\", \"small\",\n",
    "#    \"A type of model. Possible options are: small, medium, large.\")\n",
    "# flags.DEFINE_string(\"data_path\", None, \"data_path\")\n",
    "\n",
    "# FLAGS = flags.FLAGS\n",
    "\n",
    "# model = \"Larry\"\n",
    "model = \"FixedDropin\"\n",
    "data_path = \"../multimodalDBM/endomondoHR_proper.json\"\n",
    "summaries_dir = \"logs\"\n",
    "# endoFeatures = [\"speed\", \"sport\", \"heart_rate\", \"gender\", \"altitude\"]#The features we want the model to care about\n",
    "endoFeatures = [\"sport\", \"heart_rate\", \"gender\", \"altitude\", \"time_elapsed\", \"distance\", \"new_workout\", \"derived_speed\"]\n",
    "inputOrderNames = [\"new_workout\", \"derived_speed\", \"sport\", \"altitude\", \"gender\", \"distance\", \"time_elapsed\"] #add \"userId\"\n",
    "numInitialInputs = 1\n",
    "#endoFeatures = [\"sport\", \"heart_rate\", \"gender\", \"altitude\"]\n",
    "trainValTestSplit = [0.8, 0.1, 0.1]\n",
    "targetAtt = \"heart_rate\"\n",
    "lossType = \"RMSE\" #MAE, RMSE\n",
    "savePredictions = True #Save prediction and/or input sequences for later viewing of the model-data relationship\n",
    "modelRunIdentifier=datetime.datetime.now().strftime(\"%I_%M%p_%B_%d_%Y\")\n",
    "maxLoggingSteps = 1000\n",
    "interDropinInterval = 5\n",
    "zMultiple = 5\n",
    "dropInEnabled = False\n",
    "\n",
    "class EndoModel(object):\n",
    "    \"\"\"The Endomondo Contextual LSTM model.\"\"\"\n",
    "\n",
    "    def __init__(self, is_training, config, dropinManager):\n",
    "        self.is_training=is_training\n",
    "        self.batch_size = batch_size = config.batch_size\n",
    "        self.num_steps = num_steps = config.num_steps\n",
    "        self.num_layers = config.num_layers\n",
    "        size = config.hidden_size\n",
    "        # vocab_size = config.vocab_size\n",
    "        #dataDim = config.dataDim\n",
    "        inputShape = config.inputShape\n",
    "        targetShape = config.targetShape\n",
    "        pos_weight = config.pos_weight  # This is a coefficient that weights the relative importance of positive prediction error and negative prediction error. The default is 1 (equal weight.)\n",
    "\n",
    "        self._input_data = tf.placeholder(tf.float32, [batch_size*num_steps, inputShape])\n",
    "        self._targets = tf.placeholder(tf.float32, [batch_size*num_steps, targetShape])\n",
    "\n",
    "        # Slightly better results can be obtained with forget gate biases\n",
    "        # initialized to 1 but the hyperparameters of the model would need to be\n",
    "        # different than reported in the paper.\n",
    "        lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(size, forget_bias=0.0, state_is_tuple=True)\n",
    "        # Other resonable activation functions include: activation=tf.nn.relu and activation=tf.nn.softmax\n",
    "        # i.e. lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(size, forget_bias=0.0, state_is_tuple=True, activation=tf.nn.relu)\n",
    "        if is_training and config.keep_prob < 1:\n",
    "            lstm_cell = tf.nn.rnn_cell.DropoutWrapper(lstm_cell, output_keep_prob=config.keep_prob)\n",
    "        cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell] * config.num_layers, state_is_tuple=True)\n",
    "\n",
    "        self._initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "        # with tf.device(\"/cpu:0\"):\n",
    "        #  embedding = tf.get_variable(\"embedding\", [vocab_size, size])\n",
    "        #  inputs = tf.nn.embedding_lookup(embedding, self._input_data)\n",
    "        inputs = self._input_data\n",
    "\n",
    "        if is_training and config.keep_prob < 1:\n",
    "            inputs = tf.nn.dropout(inputs, config.keep_prob)\n",
    "\n",
    "        # Simplified version of tensorflow.models.rnn.rnn.py's rnn().\n",
    "        # This builds an unrolled LSTM for tutorial purposes only.\n",
    "        # In general, use the rnn() or state_saving_rnn() from rnn.py.\n",
    "        #\n",
    "        # The alternative version of the code below is:\n",
    "        #\n",
    "        #inputs = [tf.squeeze(input_, [1])\n",
    "        #          for input_ in tf.split(0, num_steps, inputs)]\n",
    "        inputs_to_save = inputs = [input_ for input_ in tf.split(0, num_steps, inputs)]\n",
    "        #print(tf.get_shape(inputs))\n",
    "        if dropInEnabled:\n",
    "            inputs = dropinManager.dropin(inputs)#Drop in component\n",
    "        #outputs, state = tf.nn.rnn(cell, inputs, initial_state=self._initial_state)\n",
    "        outputs, state = tf.nn.rnn(cell, inputs, initial_state=self._initial_state)\n",
    "\n",
    "        # Might need to change this stuff...\n",
    "        output = tf.reshape(tf.concat(1, outputs), [-1, size])\n",
    "        softmax_w = tf.Variable(tf.ones([size, targetShape]), trainable=False)\n",
    "        #softmax_b = tf.Variable(tf.ones([targetShape]), trainable=False)\n",
    "        #logits = tf.matmul(output, softmax_w) + softmax_b  # Probably need to change this...\n",
    "        logits = tf.matmul(output, softmax_w)\n",
    "        \n",
    "        variable_summaries(inputs, 'inputs')\n",
    "        variable_summaries(logits, 'logits')\n",
    "\n",
    "        # Need a new loss function here...\n",
    "        #loss = tf.nn.weighted_cross_entropy_with_logits(\n",
    "        #    [logits],\n",
    "        #    tf.reshape(self._targets, [-1, batch_size * num_steps, targetShape]),\n",
    "        #    pos_weight)\n",
    "        \n",
    "        #reshapedTargets=tf.reshape(self._targets, [-1, batch_size * num_steps, targetShape])\n",
    "        reshapedTargets=tf.reshape(self._targets, [-1, targetShape])\n",
    "        #print(tf.get_shape(reshapedTargets))\n",
    "        #print(tf.get_shape(logits))\n",
    "        logTarDiff = tf.sub(reshapedTargets, logits)\n",
    "        if lossType==\"RMSE\":#Root mean squared error\n",
    "            loss = tf.square(logTarDiff)\n",
    "        elif lossType==\"MAE\":#Mean absolute error\n",
    "            #loss = tf.reduce_mean(tf.abs(logTarDiff))\n",
    "            loss = tf.abs(logTarDiff)\n",
    "        else:\n",
    "            raise(Exception(\"Must specify a loss function\"))\n",
    "            \n",
    "        variable_summaries(loss, 'loss')\n",
    "        variable_summaries(reshapedTargets, 'targets')\n",
    "        variable_summaries(logTarDiff, 'logit-target difference')\n",
    "        # loss = tf.nn.softmax_cross_entropy_with_logits(\n",
    "        #    [logits],\n",
    "        #    [tf.reshape(self._targets, [-1])],\n",
    "        #    [tf.ones([batch_size * num_steps])])\n",
    "\n",
    "        # loss = tf.nn.seq2seq.sequence_loss_by_example(\n",
    "        #    [logits],\n",
    "        #    [tf.reshape(self._targets, [-1])],\n",
    "        #    [tf.ones([batch_size * num_steps])])\n",
    "        self.inputs = inputs_to_save\n",
    "        self.logits = logits\n",
    "        self.reshapedTargets = reshapedTargets\n",
    "        self.outputs=outputs\n",
    "        self.output=output\n",
    "        \n",
    "        self.loss = loss\n",
    "        if lossType==\"RMSE\":\n",
    "            self._cost = cost = tf.sqrt(tf.reduce_sum(loss)) / batch_size\n",
    "        elif lossType==\"MAE\":\n",
    "            self._cost = cost = tf.reduce_sum(loss) / batch_size\n",
    "        self._final_state = state\n",
    "        \n",
    "        self.merged = tf.merge_all_summaries()\n",
    "\n",
    "        if not is_training:\n",
    "            return\n",
    "\n",
    "        self._lr = tf.Variable(0.0, trainable=False)\n",
    "        tvars = tf.trainable_variables()\n",
    "        #print(tvars)\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars),\n",
    "                                          config.max_grad_norm)\n",
    "        optimizer = tf.train.GradientDescentOptimizer(self.lr)\n",
    "        self._train_op = optimizer.apply_gradients(zip(grads, tvars))\n",
    "        \n",
    "\n",
    "    def assign_lr(self, session, lr_value):\n",
    "        session.run(tf.assign(self.lr, lr_value))\n",
    "\n",
    "    @property\n",
    "    def input_data(self):\n",
    "        return self._input_data\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        return self._targets\n",
    "\n",
    "    @property\n",
    "    def initial_state(self):\n",
    "        return self._initial_state\n",
    "\n",
    "    @property\n",
    "    def cost(self):\n",
    "        return self._cost\n",
    "\n",
    "    @property\n",
    "    def final_state(self):\n",
    "        return self._final_state\n",
    "\n",
    "    @property\n",
    "    def lr(self):\n",
    "        return self._lr\n",
    "\n",
    "    @property\n",
    "    def train_op(self):\n",
    "        return self._train_op\n",
    "\n",
    "\n",
    "class ReallySmallConfig(object):\n",
    "    \"\"\"Small config.\"\"\"\n",
    "    init_scale = 0.1\n",
    "    learning_rate = 1.0\n",
    "    max_grad_norm = 5\n",
    "    num_layers = 2\n",
    "    num_steps = 40\n",
    "    hidden_size = 100\n",
    "    max_epoch = 2\n",
    "    max_max_epoch = 8\n",
    "    keep_prob = 1.0\n",
    "    lr_decay = 0.5\n",
    "    batch_size = 20\n",
    "    # vocab_size = 10000\n",
    "    dataDim = 0\n",
    "    inputShape = []\n",
    "    targetShape = []\n",
    "    pos_weight = 1\n",
    "\n",
    "\n",
    "class SmallConfig(object):\n",
    "    \"\"\"Small config.\"\"\"\n",
    "    init_scale = 0.1\n",
    "    learning_rate = 1.0\n",
    "    max_grad_norm = 5\n",
    "    num_layers = 2\n",
    "    num_steps = 20\n",
    "    hidden_size = 200\n",
    "    max_epoch = 4\n",
    "    max_max_epoch = 13\n",
    "    keep_prob = 1.0\n",
    "    lr_decay = 0.5\n",
    "    batch_size = 20\n",
    "    # vocab_size = 10000\n",
    "    dataDim = 0\n",
    "    inputShape = []\n",
    "    targetShape = []\n",
    "    pos_weight = 1\n",
    "\n",
    "\n",
    "class MediumConfig(object):\n",
    "    \"\"\"Medium config.\"\"\"\n",
    "    init_scale = 0.05\n",
    "    learning_rate = 1.0\n",
    "    max_grad_norm = 5\n",
    "    num_layers = 2\n",
    "    num_steps = 35\n",
    "    hidden_size = 650\n",
    "    max_epoch = 6\n",
    "    max_max_epoch = 39\n",
    "    keep_prob = 0.5\n",
    "    lr_decay = 0.8\n",
    "    batch_size = 20\n",
    "    # vocab_size = 10000\n",
    "    dataDim = 0\n",
    "    inputShape = []\n",
    "    targetShape = []\n",
    "    pos_weight = 1\n",
    "\n",
    "\n",
    "class LargeConfig(object):\n",
    "    \"\"\"Large config.\"\"\"\n",
    "    init_scale = 0.04\n",
    "    learning_rate = 1.0\n",
    "    max_grad_norm = 10\n",
    "    num_layers = 2\n",
    "    num_steps = 35\n",
    "    hidden_size = 1500\n",
    "    max_epoch = 14\n",
    "    max_max_epoch = 55\n",
    "    keep_prob = 0.35\n",
    "    lr_decay = 1 / 1.15\n",
    "    batch_size = 20\n",
    "    # vocab_size = 10000\n",
    "    dataDim = 0\n",
    "    inputShape = []\n",
    "    targetShape = []\n",
    "    pos_weight = 1\n",
    "\n",
    "\n",
    "class TestConfig(object):\n",
    "    \"\"\"Tiny config, for testing.\"\"\"\n",
    "    init_scale = 0.1\n",
    "    learning_rate = 1.0\n",
    "    max_grad_norm = 1\n",
    "    num_layers = 1\n",
    "    num_steps = 2\n",
    "    hidden_size = 2\n",
    "    max_epoch = 1\n",
    "    max_max_epoch = 1\n",
    "    keep_prob = 1.0\n",
    "    lr_decay = 0.5\n",
    "    batch_size = 20\n",
    "    # vocab_size = 10000\n",
    "    dataDim = 0\n",
    "    inputShape = []\n",
    "    targetShape = []\n",
    "    pos_weight = 1\n",
    "\n",
    "\n",
    "class LarryConfig(object):\n",
    "    \"\"\"Larry's custom config\"\"\"\n",
    "    init_scale = 0.05\n",
    "    learning_rate = 1.0\n",
    "    max_grad_norm = 5\n",
    "    num_layers = 2\n",
    "    num_steps = 35\n",
    "    hidden_size = 700\n",
    "    max_epoch = 12\n",
    "    max_max_epoch = 55\n",
    "    keep_prob = 0.4\n",
    "    lr_decay = 0.85\n",
    "    batch_size = 20\n",
    "    # vocab_size = 10000\n",
    "    dataDim = 0\n",
    "    inputShape = []\n",
    "    targetShape = []\n",
    "    pos_weight = 1\n",
    "    \n",
    "class fixedDropInConfig(object):\n",
    "    \"\"\"Config for dropin with a fixed interval between adding variables\"\"\"\n",
    "    init_scale = 0.05\n",
    "    learning_rate = 1.0\n",
    "    max_grad_norm = 5\n",
    "    num_layers = 2\n",
    "    num_steps = 35\n",
    "    hidden_size = 650\n",
    "    max_epoch = interDropinInterval\n",
    "    max_max_epoch = ((len(inputOrderNames)-numInitialInputs)+2)*interDropinInterval\n",
    "    keep_prob = 0.5\n",
    "    lr_decay = 0.95\n",
    "    batch_size = 20\n",
    "    # vocab_size = 10000\n",
    "    dataDim = 0\n",
    "    inputShape = []\n",
    "    targetShape = []\n",
    "    pos_weight = 1\n",
    "    \n",
    "    \n",
    "def variable_summaries(var, name):\n",
    "  \"\"\"Attach a lot of summaries to a Tensor.\"\"\"\n",
    "  with tf.name_scope('summaries'):\n",
    "    mean = tf.reduce_mean(var)\n",
    "    tf.scalar_summary('mean/' + name, mean)\n",
    "    with tf.name_scope('stddev'):\n",
    "      stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "    tf.scalar_summary('stddev/' + name, stddev)\n",
    "    tf.scalar_summary('max/' + name, tf.reduce_max(var))\n",
    "    tf.scalar_summary('min/' + name, tf.reduce_min(var))\n",
    "    #for i, val in enumerate(tf.reshape(var, [-1]).eval()):\n",
    "    #    tf.scalar_summary('full/' + name + \"_index:\" + str(i), val)\n",
    "    tf.histogram_summary(name, var)\n",
    "\n",
    "def run_epoch(session, m, data_interp, eval_op, trainValidTest, epochNum, verbose=False, writer=None):\n",
    "    \"\"\"Runs the model on the given data.\"\"\"\n",
    "    epoch_size = ((data_interp.numDataPoints // m.batch_size) - 1) // m.num_steps\n",
    "    start_time = time.time()\n",
    "    costs = 0.0\n",
    "    iters = 0\n",
    "    \n",
    "    #if (epochNum%10==0) or (epochNum%10==1):\n",
    "    #    writeEpoch=1\n",
    "    #else:\n",
    "    #    writeEpoch=0\n",
    "    writeEpoch=1     \n",
    "\n",
    "    # c and h are the two components of the lstm state tuple\n",
    "    # See https://www.tensorflow.org/versions/r0.9/api_docs/python/rnn_cell.html#classes-storing-split-rnncell-state\n",
    "    # Must handle the seperate lstm states seperately since the multiRNN class doesn't yet have a way to do this for tuple states...\n",
    "    \n",
    "    if m.num_layers==2:\n",
    "        state1_c = m.initial_state[0].c.eval()\n",
    "        state1_h = m.initial_state[0].h.eval()\n",
    "        state2_c = m.initial_state[1].c.eval()\n",
    "        state2_h = m.initial_state[1].h.eval()\n",
    "    elif m.num_layers==1:\n",
    "        state1_c = m.initial_state[0].c.eval()\n",
    "        state1_h = m.initial_state[0].h.eval()\n",
    "\n",
    "    #state1 = (state1_c, state1_h)  # the initial state of the first lstm\n",
    "    #state2 = (state2_c, state2_h)  # the initial state of the second lstm\n",
    "\n",
    "    # data_interp.newEpoch()\n",
    "    dataGen = data_interp.endoIteratorSupervised(m.batch_size, m.num_steps, trainValidTest)  # A generator over the endomondo data\n",
    "    # global dataGenTest\n",
    "    # dataGenTest = dataGen\n",
    "    # global modelTest\n",
    "    # modelTest=data_interp\n",
    "    \n",
    "    targetSeq=[]\n",
    "    logitSeq=[]\n",
    "    inputSeq=[]\n",
    "    outputsSeq=[]\n",
    "    outputSeq=[]\n",
    "    \n",
    "    for step, (x, y) in enumerate(dataGen):\n",
    "        \n",
    "        if m.num_layers==2:\n",
    "            feed_dictionary = {m.input_data: x, m.targets: y,\n",
    "                               m.initial_state[0].c: state1_c,\n",
    "                               m.initial_state[0].h: state1_h,\n",
    "                               m.initial_state[1].c: state2_c,\n",
    "                               m.initial_state[1].h: state2_h,\n",
    "                               }\n",
    "        elif m.num_layers==1:\n",
    "            feed_dictionary = {m.input_data: x, m.targets: y,\n",
    "                               m.initial_state[0].c: state1_c,\n",
    "                               m.initial_state[0].h: state1_h,\n",
    "                               }\n",
    "\n",
    "        # feed_dict.update( network.all_drop )\n",
    "        \n",
    "        #if True:\n",
    "        if m.is_training:\n",
    "            if m.num_layers==2:\n",
    "                loss, cost, state1_c, state1_h, state2_c, state2_h, summary, _ = session.run([m.loss, m.cost,\n",
    "                                                                                     m.final_state[0].c,\n",
    "                                                                                     m.final_state[0].h,\n",
    "                                                                                     m.final_state[1].c,\n",
    "                                                                                     m.final_state[1].h,\n",
    "                                                                                     m.merged,\n",
    "                                                                                     eval_op],\n",
    "                                                                                     feed_dict=feed_dictionary)\n",
    "            elif m.num_layers==1:\n",
    "                loss, cost, state1_c, state1_h, summary, _ = session.run([m.loss, m.cost,\n",
    "                                                                                     m.final_state[0].c,\n",
    "                                                                                     m.final_state[0].h,\n",
    "                                                                                     m.merged,\n",
    "                                                                                     eval_op],\n",
    "                                                                                     feed_dict=feed_dictionary)\n",
    "        \n",
    "            writer.add_summary(summary, step)\n",
    "        else:\n",
    "            if m.num_layers==2:\n",
    "                loss, cost, state1_c, state1_h, state2_c, state2_h, targets, logits, inputs, _ = session.run([m.loss, m.cost,\n",
    "                                                                                                         m.final_state[0].c,\n",
    "                                                                                                         m.final_state[0].h,\n",
    "                                                                                                         m.final_state[1].c,\n",
    "                                                                                                         m.final_state[1].h,\n",
    "                                                                                                         m.reshapedTargets,\n",
    "                                                                                                         m.logits,\n",
    "                                                                                                         m.inputs,\n",
    "                                                                                                         eval_op],\n",
    "                                                                                                         feed_dict=feed_dictionary)\n",
    "            elif m.num_layers==1:\n",
    "                loss, cost, state1_c, state1_h, targets, logits, inputs, _ = session.run([m.loss, m.cost,\n",
    "                                                                                                         m.final_state[0].c,\n",
    "                                                                                                         m.final_state[0].h,\n",
    "                                                                                                         m.reshapedTargets,\n",
    "                                                                                                         m.logits,\n",
    "                                                                                                         m.inputs,\n",
    "                                                                                                         eval_op],\n",
    "                                                                                                         feed_dict=feed_dictionary)\n",
    "                \n",
    "            if (step<maxLoggingSteps)&(savePredictions is True)&(writeEpoch==1):\n",
    "                targetSeq.extend(targets)\n",
    "                logitSeq.extend(logits)\n",
    "                #print(inputs[0])\n",
    "                inputSeq.extend(data_interp.dataDecoder(inputs[0]))\n",
    "                #inputSeq.extend(inputs)\n",
    "                #outputsSeq.extend(outputs)\n",
    "                #outputSeq.extend(output)\n",
    "\n",
    "        #state1 = (state1_c, state1_h)\n",
    "        #state2 = (state2_c, state2_h)\n",
    "        \n",
    "        \n",
    "\n",
    "        # print(cost)\n",
    "\n",
    "        costs += cost\n",
    "        iters += m.num_steps\n",
    "\n",
    "        if verbose and step % (epoch_size // 10) == 10:\n",
    "            #print(\"Step: \" + str(step))\n",
    "            # print(np.log(-costs//iters))\n",
    "            print(\"%.3f %s: %.6f speed: %.0f dpps\" %\n",
    "                  (step * 1.0 / epoch_size, lossType, (costs / iters),\n",
    "                   iters * m.batch_size / (time.time() - start_time)))\n",
    "    \n",
    "    if (m.is_training is False) & (savePredictions is True) & (writeEpoch==1):\n",
    "        print(\"Saving data to file\")\n",
    "        saveData(targetSeq, logitSeq, inputSeq, outputsSeq, outputSeq, epochNum)\n",
    "    \n",
    "    # print(costs)\n",
    "    # print(iters)\n",
    "    return (costs / iters)\n",
    "\n",
    "def saveData(targetSeq, logitSeq, inputSeq, outputsSeq, outputSeq, epochNum):\n",
    "    fileName= \"logs/fullData/\" + modelRunIdentifier + \"_epoch_\" + str(epochNum+1)\n",
    "    dataContents = dataEpoch(targetSeq, logitSeq, inputSeq, outputsSeq, outputSeq, epochNum)\n",
    "    with open(fileName, \"wb\") as f:\n",
    "            pickle.dump(dataContents, f)\n",
    "            \n",
    "class dataEpoch(object):\n",
    "    def __init__(self, targetSeq, logitSeq, inputSeq, outputsSeq, outputSeq, epochNum):\n",
    "        #self.inputSeq = inputSeq\n",
    "        self.targetSeq = targetSeq\n",
    "        self.logitSeq = logitSeq\n",
    "        #self.outputsSeq = outputsSeq\n",
    "        #self.outputSeq = outputSeq\n",
    "        self.epochNum = epochNum\n",
    "        self.endoFeatures = endoFeatures\n",
    "        self.targetAtt = targetAtt\n",
    "        self.modelType = model\n",
    "        self.lossType = lossType\n",
    "        self.trainValTestSplit = trainValTestSplit\n",
    "        self.modelRunIdentifier = modelRunIdentifier\n",
    "        self.zMultiple = zMultiple\n",
    "\n",
    "def get_config():\n",
    "    if model == \"small\":\n",
    "        return SmallConfig()\n",
    "    elif model == \"medium\":\n",
    "        return MediumConfig()\n",
    "    elif model == \"large\":\n",
    "        return LargeConfig()\n",
    "    elif model == \"test\":\n",
    "        return TestConfig()\n",
    "    elif model == \"Larry\":\n",
    "        return LarryConfig()\n",
    "    elif model == \"really small\":\n",
    "        return ReallySmallConfig()\n",
    "    elif model == \"FixedDropin\":\n",
    "        return fixedDropInConfig()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model: %s\", model)\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not data_path:\n",
    "        raise ValueError(\"Must set --data_path to PTB data directory\")\n",
    "\n",
    "    # raw_data = reader.ptb_raw_data(data_path)\n",
    "    # train_data, valid_data, test_data, _ = raw_data\n",
    "    endo_reader = dataInterpreter(fn=data_path, scaleVals=True)\n",
    "    endo_reader.buildDataSchema(endoFeatures, targetAtt, trainValTestSplit, zMultiple)\n",
    "    \n",
    "    inputIndicesDict=endo_reader.inputIndices\n",
    "\n",
    "    inputShape = endo_reader.getInputDim(targetAtt)\n",
    "    targetShape = endo_reader.getTargetDim(targetAtt)\n",
    "\n",
    "    config = get_config()\n",
    "    eval_config = get_config()\n",
    "    eval_config.batch_size = 1\n",
    "    eval_config.num_steps = 50 #Was originally set to 1\n",
    "    #config.dataDim = dataShape\n",
    "    config.inputShape = inputShape\n",
    "    config.targetShape = targetShape\n",
    "    #eval_config.dataDim = dataShape\n",
    "    eval_config.inputShape = inputShape\n",
    "    eval_config.targetShape = targetShape\n",
    "\n",
    "    with tf.Graph().as_default(), tf.Session() as session:\n",
    "        dropinManager = inputManager(inputIndicesDict, inputOrderNames, numInitialInputs)\n",
    "\n",
    "        initializer = tf.random_uniform_initializer(-config.init_scale,\n",
    "                                                    config.init_scale)\n",
    "        with tf.variable_scope(\"model\", reuse=None, initializer=initializer):\n",
    "            m = EndoModel(is_training=True, config=config, dropinManager=dropinManager)\n",
    "        with tf.variable_scope(\"model\", reuse=True, initializer=initializer):\n",
    "            mvalid = EndoModel(is_training=False, config=config, dropinManager=dropinManager)\n",
    "            mtest = EndoModel(is_training=False, config=eval_config, dropinManager=dropinManager)\n",
    "            \n",
    "        train_writer = tf.train.SummaryWriter(summaries_dir + '/train', session.graph)\n",
    "        test_writer = tf.train.SummaryWriter(summaries_dir + '/test')\n",
    "\n",
    "        tf.initialize_all_variables().run()\n",
    "\n",
    "        print(\"Starting with \" + str(dropinManager.numActiveInputs) + \" inputs\")\n",
    "        for i in range(config.max_max_epoch):\n",
    "            if dropInEnabled:\n",
    "                if i%interDropinInterval==0:\n",
    "                    #Simple drop in condition\n",
    "                    print(\"Adding input number \" + str(dropinManager.numActiveInputs+1))\n",
    "                    dropinManager.addInput()\n",
    "            epochNum=i+1\n",
    "            lr_decay = config.lr_decay ** max(i - config.max_epoch, 0.0)\n",
    "            m.assign_lr(session, config.learning_rate * lr_decay)\n",
    "\n",
    "            print(\"Epoch: %d Learning rate: %.6f\" % (i + 1, session.run(m.lr)))\n",
    "            train_perplexity = run_epoch(session, m, endo_reader, m.train_op, 'train', epochNum,\n",
    "                                         verbose=True, writer=train_writer)\n",
    "            print(\"Epoch: %d Train %s: %.6f\" % (i + 1, lossType, train_perplexity))\n",
    "            valid_perplexity = run_epoch(session, mvalid, endo_reader, tf.no_op(), 'valid', epochNum, verbose=True, writer=test_writer)\n",
    "            print(\"Epoch: %d Valid %s: %.6f\" % (i + 1, lossType, valid_perplexity))\n",
    "\n",
    "        test_perplexity = run_epoch(session, mtest, endo_reader, tf.no_op(), 'test', epochNum+1, writer=test_writer)\n",
    "        print(\"Test %s: %.4f\" % (lossType, test_perplexity))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
